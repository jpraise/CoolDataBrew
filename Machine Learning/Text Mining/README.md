# **📌 한글 텍스트 분석 및 워드클라우드 생성 프로젝트**  

## **📌 프로젝트 개요**  
이 프로젝트는 **한글 텍스트 데이터를 분석**하여 주요 단어를 추출하고 **빈도 분석 및 워드클라우드**를 생성하는 자동화 시스템입니다.  
특히, **형태소 분석(Kkma), 정규 표현식(Regex), 자연어 처리(NLP)** 기법을 활용하여 **텍스트 전처리, 단어 빈도 분석, 해시태그 추출 및 보존, 중요 키워드 필터링** 등의 기능을 수행합니다.  

---

## **🚀 주요 기능**  
✅ **이모지 및 특수 문자 제거**  
✅ **한글, 영어, 숫자만 추출하여 텍스트 정제**  
✅ **해시태그 자동 탐색 및 보존 (#해시태그 기능 유지)**  
✅ **형태소 분석(Kkma) 및 명사, 동사, 형용사 추출**  
✅ **불필요한 조사, 접속사, 문법 요소 필터링**  
✅ **사용자가 지정한 주요 단어 보존 (예: "재밌다", "체험했다" 등)**  
✅ **단어 빈도 분석 및 엑셀 저장 (`frequency_241219_kkma_hashtag.xlsx`)**  
✅ **워드클라우드 생성 및 저장 (`wordcloud_241219_kkma_hashtag.png`)**  

---

## **🎯 활용 사례**  
🔹 **SNS 및 댓글 데이터 분석 (예: 인스타그램, 트위터, 유튜브 등)**  
🔹 **해시태그 기반 키워드 트렌드 분석**  
🔹 **제품 리뷰 및 감성 분석을 위한 텍스트 마이닝**  
🔹 **주요 단어 빈도 분석 및 마케팅 전략 수립**  
🔹 **한글 자연어 처리를 활용한 데이터 전처리 자동화**  

---

## **⚙️ 설치 및 실행 방법**  

### **1️⃣ 필수 라이브러리 설치**  
아래 명령어를 실행하여 프로젝트에 필요한 라이브러리를 설치하세요.

```bash
pip install pandas openpyxl konlpy wordcloud matplotlib pillow numpy
```

📌 **Windows 사용자의 경우, `KoNLPy` 설치 후 `Java` 환경 변수를 설정해야 합니다.**  
설치 가이드: [KoNLPy 공식 문서](https://konlpy.org/en/latest/install/)  

---

### **2️⃣ 데이터 파일 준비**  
📂 분석할 **엑셀 파일**을 준비하세요.  
파일에는 `MENTION`이라는 컬럼에 분석할 텍스트 데이터가 포함되어 있어야 합니다.  
`file_path_here` 부분을 **실제 파일 경로**로 변경하세요.

```python
df = pd.read_excel(r"file_path_here", engine='openpyxl')
```

---

### **3️⃣ 코드 실행**  
다음 명령어를 실행하여 분석을 시작하세요.

```bash
python script.py
```

✅ **코드 실행 후, 주요 단어 분석 결과가 엑셀 파일(`frequency_241219_kkma_hashtag.xlsx`)로 저장됩니다.**  
✅ **워드클라우드가 자동으로 생성되어 `wordcloud_241219_kkma_hashtag.png`로 저장됩니다.**  

---

## **📊 출력 결과 (Excel 파일 및 워드클라우드)**  

### **📄 생성되는 파일**  
✅ **단어 빈도 분석 결과 (`frequency_241219_kkma_hashtag.xlsx`)**  
✅ **워드클라우드 이미지 (`wordcloud_241219_kkma_hashtag.png`)**  

### **📌 엑셀 파일 구조 예시 (`frequency_241219_kkma_hashtag.xlsx`)**  

| comment_id   | word_fragment | word_type  | word_count |
|-------------|--------------|------------|------------|
| COMMENT_0001 | 체험했다     | PRESERVED  | 3          |
| COMMENT_0002 | 재밌다       | PRESERVED  | 2          |
| COMMENT_0003 | #뷰티       | HASHTAG    | 5          |
| COMMENT_0004 | 놀랐다       | PRESERVED  | 1          |
| COMMENT_0005 | 센슈얼       | PRESERVED  | 4          |

📌 **컬럼 설명**  
- `comment_id`: 분석된 댓글 또는 문장의 고유 ID  
- `word_fragment`: 추출된 단어 또는 해시태그  
- `word_type`: 단어 유형 (예: 명사(NNG), 동사(VV), 해시태그(HASHTAG), 보존된 단어(PRESERVED))  
- `word_count`: 해당 단어가 등장한 횟수  

---

### **📌 워드클라우드**  
✅ **빈도수가 높은 단어일수록 크게 표시됩니다.**  
✅ **해시태그가 별도로 보존되어 분석 결과에 반영됩니다.**  


---

## **📢 주요 분석 로직 설명**  

### **1️⃣ 텍스트 전처리 과정**
🔹 **이모지 및 특수 문자 제거** (`remove_emojis()`)  
🔹 **영문, 한글, 숫자만 추출** (`clean_text()`)  
🔹 **해시태그 보존 및 복원** (`clean_text()`)  

### **2️⃣ 형태소 분석 (KoNLPy - Kkma)**
🔹 **형태소 분석을 통해 명사(NNG), 동사(VV), 형용사(VA) 등을 추출**  
🔹 **특정 단어(`preserve_words`)는 변형 없이 그대로 유지**  
🔹 **불필요한 단어(`excluded_words`) 제거**  

### **3️⃣ 단어 빈도 분석 및 데이터 정리**
🔹 **각 단어별 등장 횟수를 계산하여 엑셀 저장 (`return_dataframes()`)**  
🔹 **불필요한 조사 및 문법 요소 제거 (`excluded_words`)**  

### **4️⃣ 워드클라우드 생성 (`create_wordcloud()`)**
🔹 **빈도수가 높은 단어를 시각적으로 표현**  
🔹 **사용자가 설정한 한글 폰트 적용 (Windows 사용자는 직접 경로 설정 필요)**  

---

## **📢 기여 및 문의**  
이 프로젝트에 기여하고 싶거나 문의사항이 있다면 **깃허브 이슈**를 통해 의견을 남겨주세요! 🚀  
